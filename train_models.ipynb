{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import Utils\n",
    "import skseq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839149, 3) (837339, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id          words tags\n",
       "0            0      Thousands    O\n",
       "1            0             of    O\n",
       "2            0  demonstrators    O\n",
       "3            0           have    O\n",
       "4            0        marched    O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Utils.assignment_2_functions import *\n",
    "\n",
    "df_train = pd.read_csv(\"./data/train_data_ner.csv\", encoding=\"latin1\")\n",
    "df_test  = pd.read_csv(\"./data/test_data_ner.csv\", encoding=\"latin1\")\n",
    "\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train set there are 38366 sentences\n",
      "In test set there are 38367 sentences\n",
      "There are 17 diferent tags\n"
     ]
    }
   ],
   "source": [
    "print('In train set there are {} sentences'.format(len(set(df_train.sentence_id))))\n",
    "print('In test set there are {} sentences'.format(len(set(df_test.sentence_id))))\n",
    "\n",
    "print('There are {} diferent tags'.format(len(set(df_train.tags))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags:\n",
    "\n",
    "```\n",
    "geo = Geographical Entity\n",
    "org = Organization\n",
    "per = Person\n",
    "gpe = Geopolitical Entity\n",
    "tim = Time indicator\n",
    "art = Artifact\n",
    "eve = Event\n",
    "nat = Natural Phenomenon\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building word to position map and his inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55145 words in the corpus\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_pos, pos_to_word = get_corpus_and_word_dict(df_train,df_test)\n",
    "print('There are {} words in the corpus'.format(len(word_to_pos)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building tag to position map and his inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 tags\n"
     ]
    }
   ],
   "source": [
    "tag_to_pos, pos_to_tag = get_tag_dict(df_train)\n",
    "print('There are {} tags'.format(len(tag_to_pos)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a function to get all the sentences in different list of tokens. And all the tags in different lists of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr,Y_tr = get_X_Y(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['They',\n",
       "  'left',\n",
       "  'after',\n",
       "  'a',\n",
       "  'tense',\n",
       "  'hour-long',\n",
       "  'standoff',\n",
       "  'with',\n",
       "  'riot',\n",
       "  'police',\n",
       "  '.'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[2], Y_tr[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "tag_pos_dict = LabelDictionary(tag_to_pos.keys())\n",
    "word_pos_dict = LabelDictionary(word_to_pos.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the SequenceList => List of Sequence obects with word_pos/tag_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences.sequence_list import SequenceList\n",
    "train_seq = SequenceList(word_pos_dict, tag_pos_dict)\n",
    "for x,y in zip(X_tr,Y_tr):\n",
    "    train_seq.add_sequence(x, y, word_pos_dict, tag_pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15045/16 43294/16 28745/7 48506/16 46162/16 43633/16 44134/16 53065/16 24527/2 53627/16 49800/16 21/16 54800/16 45749/16 31501/5 46165/16 36595/16 37209/16 53335/16 43478/16 42381/16 53335/16 36916/16 36261/16 40947/16 46176/16 47225/16 44134/16 46751/16 30358/2 34003/10 24/16 ,\n",
       " 'Helicopter/O gunships/O Saturday/B-tim pounded/O militant/O hideouts/O in/O the/O Orakzai/B-geo tribal/O region/O ,/O where/O many/O Taliban/B-org militants/O are/O believed/O to/O have/O fled/O to/O avoid/O an/O earlier/O military/O offensive/O in/O nearby/O South/B-geo Waziristan/I-geo ./O ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[1], train_seq[1].to_words(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build IDFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sentence is given by 4 parts: init, trans, fin and emi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features: [[0]]\n",
      "Transition features: [[3], [32], [34], [3], [3], [3], [3], [9], [11], [3], [3], [3], [3], [44], [46], [3], [3], [3], [3], [3], [3], [3], [3], [3], [3], [3], [3], [3], [9], [58], [59]]\n",
      "Final features: [[28]]\n",
      "Emission features: [[29], [30], [31], [33], [35], [36], [15], [13], [37], [38], [39], [40], [41], [42], [43], [45], [47], [48], [10], [5], [49], [10], [50], [51], [52], [53], [54], [15], [55], [56], [57], [27]]\n"
     ]
    }
   ],
   "source": [
    "id_seq=1\n",
    "\n",
    "print (\"Initial features:\",     feature_mapper.feature_list[id_seq][0])\n",
    "print (\"Transition features:\",  feature_mapper.feature_list[id_seq][1])\n",
    "print (\"Final features:\",       feature_mapper.feature_list[id_seq][2])\n",
    "print (\"Emission features:\",    feature_mapper.feature_list[id_seq][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the base model there are 39802 features\n"
     ]
    }
   ],
   "source": [
    "print('In the base model there are {} features'.format(len(feature_mapper.feature_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding extra features\n",
    "from skseq.sequences import extended_feature\n",
    "feature_mapper2 = skseq.sequences.extended_feature.ExtendedFeatures(train_seq)\n",
    "feature_mapper2.build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the feat model there are 158055 features\n"
     ]
    }
   ],
   "source": [
    "print('In the feat model there are {} features'.format(len(feature_mapper2.feature_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq.sequences.structured_perceptron as spc\n",
    "\n",
    "sp = spc.StructuredPerceptron(word_pos_dict, tag_pos_dict, feature_mapper)\n",
    "sp2 = spc.StructuredPerceptron(word_pos_dict, tag_pos_dict, feature_mapper2)\n",
    "\n",
    "sp.num_epochs = 1\n",
    "sp.fit(feature_mapper.dataset, sp.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.945339\n",
      "Epoch: 1 Accuracy: 0.953404\n",
      "Epoch: 2 Accuracy: 0.956288\n",
      "Epoch: 3 Accuracy: 0.957609\n",
      "Epoch: 4 Accuracy: 0.959090\n",
      "Epoch: 5 Accuracy: 0.960163\n",
      "Epoch: 6 Accuracy: 0.960788\n",
      "Epoch: 7 Accuracy: 0.961633\n",
      "Epoch: 8 Accuracy: 0.961799\n",
      "Epoch: 9 Accuracy: 0.962740\n",
      "Epoch: 10 Accuracy: 0.963002\n",
      "Epoch: 11 Accuracy: 0.963532\n",
      "Epoch: 12 Accuracy: 0.963861\n",
      "Epoch: 13 Accuracy: 0.964186\n",
      "Epoch: 14 Accuracy: 0.964215\n"
     ]
    }
   ],
   "source": [
    "sp2.num_epochs = 1\n",
    "sp2.fit(feature_mapper2.dataset, sp.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the models' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_model(\"./fitted_models/perceptron_base_1_epoch\")\n",
    "sp2.save_model(\"./fitted_models/perceptron_extra_1_epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
